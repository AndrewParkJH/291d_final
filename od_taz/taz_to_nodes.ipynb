{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbpresent": {
     "id": "70cafb46-dca6-422e-8be0-5226fbca50b3"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ox 2.0.0\n",
      "nx 3.4.2\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os, zipfile, requests, pandas as pd, geopandas as gpd, osmnx as ox, networkx as nx\n",
    "import ast\n",
    "import statistics\n",
    "import numpy as np\n",
    "from sklearn.neighbors import BallTree\n",
    "from shapely.geometry import Point\n",
    "import random\n",
    "import matplotlib.path as mpltPath\n",
    "import json \n",
    "\n",
    "ox.settings.use_cache = True\n",
    "ox.settings.log_console = True\n",
    "print('ox {}\\nnx {}'.format(ox.__version__, nx.__version__))\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get all TAZs for the Bay Area and all trips from the Bay Area MTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbpresent": {
     "id": "4354d77f-1d49-403a-b703-f344dbb699c7"
    }
   },
   "outputs": [],
   "source": [
    "taz_loc_df = pd.read_csv(\"/home/rishi/Berkeley/LPSim/LPSim/transportation_analysis_zones_1454_3081571714501117281.csv\")\n",
    "trips_df = pd.read_csv(\"/home/rishi/Berkeley/LPSim/LPSim/sf_mtc_od.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_x</th>\n",
       "      <th>y_x</th>\n",
       "      <th>x_y</th>\n",
       "      <th>y_y</th>\n",
       "      <th>time_departure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.397449</td>\n",
       "      <td>37.792642</td>\n",
       "      <td>-122.402791</td>\n",
       "      <td>37.792859</td>\n",
       "      <td>36555.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.398992</td>\n",
       "      <td>37.794292</td>\n",
       "      <td>-122.400959</td>\n",
       "      <td>37.792116</td>\n",
       "      <td>33181.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.396480</td>\n",
       "      <td>37.793665</td>\n",
       "      <td>-122.400959</td>\n",
       "      <td>37.792116</td>\n",
       "      <td>31361.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.398992</td>\n",
       "      <td>37.794292</td>\n",
       "      <td>-122.401152</td>\n",
       "      <td>37.793067</td>\n",
       "      <td>28975.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.397404</td>\n",
       "      <td>37.792440</td>\n",
       "      <td>-122.399785</td>\n",
       "      <td>37.792261</td>\n",
       "      <td>27926.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x_x        y_x         x_y        y_y  time_departure\n",
       "0 -122.397449  37.792642 -122.402791  37.792859         36555.8\n",
       "1 -122.398992  37.794292 -122.400959  37.792116         33181.4\n",
       "2 -122.396480  37.793665 -122.400959  37.792116         31361.4\n",
       "3 -122.398992  37.794292 -122.401152  37.793067         28975.4\n",
       "4 -122.397404  37.792440 -122.399785  37.792261         27926.8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trips_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Narrow down trips to only morning trips between 8-9am (morning peak) and also only to car trips (both driving and ridesharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "5588c773-009c-40c4-a4be-8ec512d71d20"
    }
   },
   "outputs": [],
   "source": [
    "#get only peak morning trips and the shape\n",
    "depart_hour = 8\n",
    "morning_peak = trips_df[\n",
    "    (trips_df.time_departure >= (depart_hour) * 3600) & \n",
    "    (trips_df.time_departure <= (depart_hour + 2) * 3600)\n",
    "] #| (trips_df.depart_hour == 9)]\n",
    "morning_peak.shape\n",
    "\n",
    "time_string = '{}to{}'.format(depart_hour, depart_hour + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbpresent": {
     "id": "c5a18b9f-0129-4cdf-b8d2-ef4376eaf53e"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56447, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get full car trips from O to D (this includes ridesharing, but does not include car to another form of transit)\n",
    "#morning_peak = morning_peak[morning_peak.trip_mode < 7]\n",
    "morning_peak.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbpresent": {
     "id": "d403d3eb-9c82-4178-9d24-d4e2cd533ef2"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_x</th>\n",
       "      <th>y_x</th>\n",
       "      <th>x_y</th>\n",
       "      <th>y_y</th>\n",
       "      <th>time_departure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.398992</td>\n",
       "      <td>37.794292</td>\n",
       "      <td>-122.401152</td>\n",
       "      <td>37.793067</td>\n",
       "      <td>28975.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>-122.398610</td>\n",
       "      <td>37.792413</td>\n",
       "      <td>-122.406982</td>\n",
       "      <td>37.789436</td>\n",
       "      <td>28891.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>-122.398298</td>\n",
       "      <td>37.791734</td>\n",
       "      <td>-122.406794</td>\n",
       "      <td>37.788501</td>\n",
       "      <td>28919.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>-122.396401</td>\n",
       "      <td>37.793249</td>\n",
       "      <td>-122.408275</td>\n",
       "      <td>37.778852</td>\n",
       "      <td>28954.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>-122.398298</td>\n",
       "      <td>37.791734</td>\n",
       "      <td>-122.389431</td>\n",
       "      <td>37.788852</td>\n",
       "      <td>28894.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            x_x        y_x         x_y        y_y  time_departure\n",
       "3   -122.398992  37.794292 -122.401152  37.793067         28975.4\n",
       "43  -122.398610  37.792413 -122.406982  37.789436         28891.3\n",
       "57  -122.398298  37.791734 -122.406794  37.788501         28919.4\n",
       "84  -122.396401  37.793249 -122.408275  37.778852         28954.0\n",
       "159 -122.398298  37.791734 -122.389431  37.788852         28894.3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morning_peak.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create functions to find the nodes that are within the polygons of each TAZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_in_nodes(row, points, nodes_df):\n",
    "    ### return the indices of points in nodes_df that are contained in row['geometry']\n",
    "    if row['geometry'].type == 'MultiPolygon':\n",
    "        return []\n",
    "    else:\n",
    "        path = mpltPath.Path(list(zip(*row['geometry'].exterior.coords.xy)))\n",
    "        in_index = path.contains_points(points)\n",
    "        return nodes_df['osmid'].loc[in_index].tolist()\n",
    "\n",
    "\n",
    "def taz_nodes():\n",
    "    ### Find corresponding nodes for each TAZ\n",
    "    ### Input 1: TAZ polyline\n",
    "    taz_gdf = gpd.read_file(\"/home/rishi/Berkeley/LPSim/LPSim/transportation_analysis_zones_1454.shp\")\n",
    "    #taz_gdf = gpd.read_file(\"san_francisco_taz.json\")\n",
    "    taz_gdf = taz_gdf.to_crs({'init': 'epsg:4326'})\n",
    "\n",
    "    ### Input 2: OSM nodes coordinate\n",
    "    nodes_df = pd.read_csv('../new_full_network/nodes.csv') ### `nodes.csv` from OSMNX\n",
    "    points = nodes_df[['x', 'y']].values ### x, y are the coordinates of the nodes\n",
    "    taz_gdf['in_nodes'] = taz_gdf.apply(lambda row: find_in_nodes(row, points, nodes_df), axis=1)\n",
    "    taz_nodes_dict = {row['taz1454']:row['in_nodes'] for index, row in taz_gdf.iterrows()}\n",
    "    \n",
    "    return taz_nodes_dict\n",
    "    ### [{'taz': 1, 'in_nodes': '[...]''}, ...]\n",
    "    #with open('taz_nodes.json', 'w') as outfile:\n",
    "    #    json.dump(taz_nodes_dict, outfile, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishi/miniconda3/envs/lpsim/lib/python3.13/site-packages/pyogrio/raw.py:198: RuntimeWarning: /home/rishi/Berkeley/LPSim/LPSim/transportation_analysis_zones_1454.shp contains polygon(s) with rings with invalid winding order. Autocorrecting them, but that shapefile should be corrected using ogr2ogr for example.\n",
      "  return ogr_read(\n",
      "/home/rishi/miniconda3/envs/lpsim/lib/python3.13/site-packages/pyproj/crs/crs.py:143: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  in_crs_string = _prepare_from_proj_string(in_crs_string)\n",
      "/tmp/ipykernel_423186/3531716854.py:3: ShapelyDeprecationWarning: The 'type' attribute is deprecated, and will be removed in the future. You can use the 'geom_type' attribute instead.\n",
      "  if row['geometry'].type == 'MultiPolygon':\n"
     ]
    }
   ],
   "source": [
    "taz_nodes_dict = taz_nodes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count the number of TAZs that do not have any nodes in its network (for informational purposes/sanity check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "#number of TAZ that do not have any nodes in its network\n",
    "count = 0\n",
    "for key, value in taz_nodes_dict.items():\n",
    "    if len(taz_nodes_dict[key]) == 0:\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create functions to (a) generate a dataframe containing all OD from TAZ to TAZ, and then (b) randomly assign each O to a particular node in the TAZ and each D to a particular node in the TAZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframe of each person with origin TAZ and destination TAZ\n",
    "def create_od_df(trips_df):\n",
    "    orig_dest_df = pd.DataFrame(columns=['orig', 'dest'])\n",
    "    orig_dest_df['orig'] = morning_peak['orig_taz']\n",
    "    orig_dest_df['dest'] = morning_peak['dest_taz']\n",
    "    orig_dest_df['dep_time'] = morning_peak['time_departure']\n",
    "    #orig_dest_df['person_num'] = morning_peak['person_num']\n",
    "    return orig_dest_df\n",
    "\n",
    "def assign_node_to_od(od_df, taz_nodes_dict, assign='random'):\n",
    "    origs = []\n",
    "    dests = []\n",
    "    bad_list = []\n",
    "    for i, row in enumerate(od_df.itertuples(), 0):\n",
    "        len_network_o = len(taz_nodes_dict[row.orig])\n",
    "        len_network_d = len(taz_nodes_dict[row.dest])\n",
    "        if len_network_o == 0 or len_network_d == 0:\n",
    "            bad_list += [i,]\n",
    "        else:\n",
    "            if assign == 'random':\n",
    "                node_o = random.choice(taz_nodes_dict[row.orig])\n",
    "                node_d = random.choice(taz_nodes_dict[row.dest])\n",
    "                #print(node_o)\n",
    "                #print(node_d)\n",
    "        \n",
    "                origs += [node_o,]\n",
    "                dests += [node_d,]\n",
    "                \n",
    "    print(\"number of OD taz with zero nodes = {}\".format(len(bad_list)))\n",
    "    return origs, dests, bad_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishi/miniconda3/envs/lpsim/lib/python3.13/site-packages/pyogrio/raw.py:198: RuntimeWarning: /home/rishi/Berkeley/LPSim/LPSim/transportation_analysis_zones_1454.shp contains polygon(s) with rings with invalid winding order. Autocorrecting them, but that shapefile should be corrected using ogr2ogr for example.\n",
      "  return ogr_read(\n"
     ]
    }
   ],
   "source": [
    "taz_gdf = gpd.read_file(\"/home/rishi/Berkeley/LPSim/LPSim/transportation_analysis_zones_1454.shp\")\n",
    "taz_gdf = taz_gdf.to_crs(epsg=4326)  # Ensure it matches your coordinates' CRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_423186/1794825078.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  morning_peak['orig_geometry'] = morning_peak.apply(lambda row: Point(row['x_x'], row['y_x']), axis=1)\n",
      "/tmp/ipykernel_423186/1794825078.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  morning_peak['dest_geometry'] = morning_peak.apply(lambda row: Point(row['x_y'], row['y_y']), axis=1)\n"
     ]
    }
   ],
   "source": [
    "# Convert origin and destination coordinates to Points\n",
    "morning_peak['orig_geometry'] = morning_peak.apply(lambda row: Point(row['x_x'], row['y_x']), axis=1)\n",
    "morning_peak['dest_geometry'] = morning_peak.apply(lambda row: Point(row['x_y'], row['y_y']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_423186/2371353421.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  morning_peak['orig_taz'] = orig_with_taz['taz1454']\n",
      "/tmp/ipykernel_423186/2371353421.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  morning_peak['dest_taz'] = dest_with_taz['taz1454']\n"
     ]
    }
   ],
   "source": [
    "orig_gdf = gpd.GeoDataFrame(morning_peak, geometry='orig_geometry', crs=\"EPSG:4326\")\n",
    "dest_gdf = gpd.GeoDataFrame(morning_peak, geometry='dest_geometry', crs=\"EPSG:4326\")\n",
    "\n",
    "# Spatial join to find TAZs\n",
    "orig_with_taz = gpd.sjoin(orig_gdf, taz_gdf[['taz1454', 'geometry']], how=\"left\", predicate='intersects')\n",
    "dest_with_taz = gpd.sjoin(dest_gdf, taz_gdf[['taz1454', 'geometry']], how=\"left\", predicate='intersects')\n",
    "\n",
    "# Add TAZ columns to morning_peak DataFrame\n",
    "morning_peak['orig_taz'] = orig_with_taz['taz1454']\n",
    "morning_peak['dest_taz'] = dest_with_taz['taz1454']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                x_x        y_x         x_y        y_y  time_departure  \\\n",
      "3       -122.398992  37.794292 -122.401152  37.793067         28975.4   \n",
      "43      -122.398610  37.792413 -122.406982  37.789436         28891.3   \n",
      "57      -122.398298  37.791734 -122.406794  37.788501         28919.4   \n",
      "84      -122.396401  37.793249 -122.408275  37.778852         28954.0   \n",
      "159     -122.398298  37.791734 -122.389431  37.788852         28894.3   \n",
      "...             ...        ...         ...        ...             ...   \n",
      "2819273 -122.493352  37.853609 -122.519445  37.973755         28842.7   \n",
      "2819276 -122.480695  37.837944 -122.512136  37.964002         28881.1   \n",
      "2819312 -122.480319  37.837677 -122.530585  37.898376         28919.9   \n",
      "2819365 -122.562390  37.899031 -122.525394  37.874967         28956.7   \n",
      "2819384 -122.570881  37.913599 -122.540335  37.892252         28979.9   \n",
      "\n",
      "                                   orig_geometry  \\\n",
      "3                POINT (-122.3989918 37.7942922)   \n",
      "43               POINT (-122.3986103 37.7924133)   \n",
      "57       POINT (-122.3982976 37.791734000000005)   \n",
      "84               POINT (-122.3964008 37.7932487)   \n",
      "159      POINT (-122.3982976 37.791734000000005)   \n",
      "...                                          ...   \n",
      "2819273          POINT (-122.4933521 37.8536093)   \n",
      "2819276   POINT (-122.48069479999998 37.8379436)   \n",
      "2819312          POINT (-122.4803195 37.8376773)   \n",
      "2819365          POINT (-122.5623896 37.8990307)   \n",
      "2819384          POINT (-122.5708807 37.9135988)   \n",
      "\n",
      "                                   dest_geometry  orig_taz  dest_taz  \n",
      "3                POINT (-122.4011522 37.7930673)       1.0       2.0  \n",
      "43               POINT (-122.4069817 37.7894357)       1.0       5.0  \n",
      "57               POINT (-122.4067939 37.7885009)       1.0       5.0  \n",
      "84               POINT (-122.4082752 37.7788519)       1.0      11.0  \n",
      "159       POINT (-122.3894308 37.78885220000001)       1.0      16.0  \n",
      "...                                          ...       ...       ...  \n",
      "2819273   POINT (-122.51944509999998 37.9737548)    1453.0    1427.0  \n",
      "2819276   POINT (-122.51213590000002 37.9640024)    1453.0    1428.0  \n",
      "2819312          POINT (-122.5305848 37.8983763)    1453.0    1442.0  \n",
      "2819365  POINT (-122.5253943 37.874967100000006)    1453.0    1450.0  \n",
      "2819384          POINT (-122.5403347 37.8922515)    1453.0    1451.0  \n",
      "\n",
      "[56447 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "print(morning_peak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orig</th>\n",
       "      <th>dest</th>\n",
       "      <th>dep_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>28975.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>28891.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>28919.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>28954.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>28894.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     orig  dest  dep_time\n",
       "3     1.0   2.0   28975.4\n",
       "43    1.0   5.0   28891.3\n",
       "57    1.0   5.0   28919.4\n",
       "84    1.0  11.0   28954.0\n",
       "159   1.0  16.0   28894.3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morning_peak_od_df = create_od_df(morning_peak)\n",
    "morning_peak_od_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orig</th>\n",
       "      <th>dest</th>\n",
       "      <th>dep_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>28975.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>28891.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>28919.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>28954.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>28894.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     orig  dest  dep_time\n",
       "3     1.0   2.0   28975.4\n",
       "43    1.0   5.0   28891.3\n",
       "57    1.0   5.0   28919.4\n",
       "84    1.0  11.0   28954.0\n",
       "159   1.0  16.0   28894.3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = morning_peak_od_df.copy()\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = new_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of OD taz with zero nodes = 3\n",
      "time taken = 0.20865988731384277\n"
     ]
    }
   ],
   "source": [
    "#create dataframe that contains ODs from randomly assigned node in O taz to randomly assigned node in D taz\n",
    "start = time.time()\n",
    "origs, dests, bad_list = assign_node_to_od(new_df, taz_nodes_dict, 'random')\n",
    "end = time.time()\n",
    "print(\"time taken = {}\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(bad_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = new_df.drop(new_df.index[bad_list])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make final dataframe that is in the SAMPN, PERNO, orig, dest format of OD for the traffic microsimulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new dataframe with person id, person num, orig OSMID, and dest OSMID\n",
    "def make_final_df(origs, dests, morning_peak):\n",
    "    #osmid_o = [x['osmid'] for x in origs]\n",
    "    #osmid_d = [x['osmid'] for x in dests]\n",
    "    final_df = pd.DataFrame(columns=['SAMPN', 'PERNO','orig', 'dest'])\n",
    "    final_df['SAMPN'] = morning_peak['person_id']\n",
    "    final_df['PERNO'] = 1\n",
    "    final_df['orig'] = origs\n",
    "    final_df['dest'] = dests\n",
    "\n",
    "    return final_df\n",
    "\n",
    "final_od_file_df = make_final_df(origs, dests, final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new dataframe with person id, person num, orig OSMID, and dest OSMID\n",
    "def make_final_df_deptime(origs, dests, morning_peak):\n",
    "    #osmid_o = [x['osmid'] for x in origs]\n",
    "    #osmid_d = [x['osmid'] for x in dests]\n",
    "    final_df = pd.DataFrame(columns=['dep_time','orig', 'dest'])\n",
    "    final_df['dep_time'] = morning_peak['dep_time']\n",
    "    final_df['origin'] = origs\n",
    "    final_df['destination'] = dests\n",
    "\n",
    "    return final_df\n",
    "\n",
    "final_od_file_df = make_final_df_deptime(origs, dests, final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56441, 5)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_od_file_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the OD file as od_demand.csv to be used in the traffic microsimulator, cb-cities, and static traffic assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to csv\n",
    "final_od_file_df.to_csv('../new_full_network/od_demand.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNUSED STUFF #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the osmid in nodes.csv and compare to the osmids of origins and destinations in the final_df dataframe to see which ones are there and which ones are not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_df = pd.read_csv(\"../nodes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vals_orig = final_df.orig.isin(nodes_df.osmid).astype(int)\n",
    "print(\"# of origin nodes in OD file not in nodes file = {}\".format(count_vals_orig.sum()))\n",
    "\n",
    "count_vals_dest = final_df.dest.isin(nodes_df.osmid).astype(int)\n",
    "print(\"# of dest nodes in OD file not in nodes file = {}\".format(count_vals_dest.sum()))\n",
    "            \n",
    "#print(\"orig count not in nodes file = {}\".format(orig_count))\n",
    "#print(\"dest count not in nodes file = {}\".format(dest_count))\n",
    "#print(\"total count not in nodes file = {}\".format(orig_count + dest_count))\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for idx, row in final_od_file_df.iterrows():\n",
    "    if row['orig'] == row['dest']:\n",
    "        #print(row['orig'], row['dest'])\n",
    "        count += 1\n",
    "        \n",
    "        \n",
    "print(\"# of OD pairs with same src and dest = {}\".format(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframe of each person with origin TAZ and destination TAZ\n",
    "def create_od_df(trips_df):\n",
    "    orig_dest_df = pd.DataFrame(columns=['orig', 'dest'])\n",
    "    orig_dest_df['orig'] = morning_peak['orig_taz']\n",
    "    orig_dest_df['dest'] = morning_peak['dest_taz']\n",
    "    return orig_dest_df\n",
    "\n",
    "def assign_node_to_od(od_df, taz_street_network, assign='random'):\n",
    "    new_df = od_df.copy()\n",
    "    origs = []\n",
    "    dests = []\n",
    "    for index, row in od_df.iterrows():\n",
    "        #get the lengths of the networks so that we can randomly choose a number in those ranges\n",
    "        len_network_o = len(taz_graph_list[row['orig']].nodes())\n",
    "        len_network_d = len(taz_graph_list[row['dest']].nodes())\n",
    "        \n",
    "        if assign == 'random':\n",
    "            #get the randomly chosen value within the length range\n",
    "            rand_val_o = randint(0, len_network_o - 1)\n",
    "            rand_val_d = randint(0, len_network_d - 1)\n",
    "        \n",
    "        #make the network nodes of origin and destination taz lists\n",
    "        list_of_taz_nodes_o = list(taz_graph_list[row['orig']].nodes())\n",
    "        list_of_taz_nodes_d = list(taz_graph_list[row['dest']].nodes())\n",
    "        #print(list_of_taz_nodes_o)\n",
    "        \n",
    "        #get the OSMID of the nodes from the above lists based on the random value as the index\n",
    "        taz_graph_node_index_o = list_of_taz_nodes_o[rand_val_o]\n",
    "        taz_graph_node_index_d = list_of_taz_nodes_d[rand_val_d]\n",
    "        #print(taz_graph_node_index_o)\n",
    "        \n",
    "        #set the new nodes as that person's O and D\n",
    "        node_o = taz_graph_list[row['orig']].node[taz_graph_node_index_o]\n",
    "        #print(node_o)\n",
    "        node_d = taz_graph_list[row['dest']].node[taz_graph_node_index_d]\n",
    "        #print(node_d)\n",
    "        \n",
    "        origs += [node_o,]\n",
    "        dests += [node_d,]\n",
    "        \n",
    "    return origs, dests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#make each TAZ a graph with its street netowrks\n",
    "taz_graph_list = []\n",
    "taz_num = 0\n",
    "start = time.time()\n",
    "for x in taz['geometry']:\n",
    "    polygon_hull = x.convex_hull\n",
    "    polygon_hull_proj, crs = ox.project_geometry(polygon_hull)\n",
    "    polygon_hull_proj_buff = polygon_hull_proj.buffer(200) #200 meters\n",
    "    polygon_hull_buff, crs = ox.project_geometry(polygon_hull_proj_buff, crs=crs, to_latlong=True)\n",
    "    try:\n",
    "        G = ox.graph_from_polygon(polygon_hull_buff, network_type='drive', simplify=True) \n",
    "    except: \n",
    "        print('An error occurred.')\n",
    "    #latlng_geom, _ = ox.project_geometry(taz['geometry'].iloc[0], crs={'init':'epsg:28992'}, to_latlong=True)\n",
    "    #print(\"taz num = {}\".format(taz_num))\n",
    "    #print(\"num nodes = {}\".format(len(G.nodes())))\n",
    "    taz_graph_list += [G,]\n",
    "    taz_num += 1\n",
    "end_time = time.time()\n",
    "print(\"total time = {}\".format(abs(end_time - start_time)))\n",
    "#ox.plot_graph(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ox.plot_graph(taz_graph_list[400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "taz_graph_list[400].node[65303936]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to do the OD assignment in each taz another way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create full bay area street network\n",
    "#identify bay area counties by fips code\n",
    "bayarea = {'Alameda':'001',\n",
    "           'Contra Costa':'013',\n",
    "           'Marin':'041',\n",
    "           'Napa':'055',\n",
    "           'San Francisco':'075',\n",
    "           'San Mateo':'081',\n",
    "           'Santa Clara':'085',\n",
    "           'Solano':'095',\n",
    "           'Sonoma':'097'\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shapefile of counties\n",
    "counties_shapefile_dir = 'cb_2016_us_county_500k'\n",
    "counties = gpd.read_file(\"{}.shp\".format(counties_shapefile_dir))\n",
    "len(counties)\n",
    "\n",
    "# retain only those tracts that are in the bay area counties\n",
    "mask = (counties['STATEFP'] == '06') & (counties['COUNTYFP'].isin(bayarea.values()))\n",
    "gdf_bay = counties[mask]\n",
    "len(gdf_bay)\n",
    "\n",
    "bayarea_polygon = gdf_bay.unary_union\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the convex hull, otherwise we'll cut out bridges over the bay\n",
    "bayarea_polygon_hull = bayarea_polygon.convex_hull\n",
    "bayarea_polygon_hull_proj, crs = ox.project_geometry(bayarea_polygon_hull)\n",
    "bayarea_polygon_hull_proj\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project by a mile to get connectivities surrounding our O-Ds\n",
    "bayarea_polygon_hull_proj_buff = bayarea_polygon_hull_proj.buffer(1600) #1 mile in meters\n",
    "bayarea_polygon_hull_buff, crs = ox.project_geometry(bayarea_polygon_hull_proj_buff, crs=crs, to_latlong=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make overall bay area network\n",
    "G = ox.graph_from_polygon(bayarea_polygon_hull_buff, network_type='drive', simplify=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify all the edge types we want to retain\n",
    "types = ['motorway', 'motorway_link', 'trunk', 'trunk_link', \n",
    "         'primary', 'primary_link', 'secondary', 'secondary_link',\n",
    "         'tertiary', 'tertiary_link', 'unclassified', 'road']\n",
    "\n",
    "\n",
    "#types = ['motorway', 'motorway_link', \n",
    "#         'primary', 'primary_link', 'secondary', 'secondary_link',\n",
    "#         'tertiary', 'tertiary_link']\n",
    "\n",
    "minor_streets = [(u, v, k) for u, v, k, d in G.edges(keys=True, data=True) if d['highway'] not in types]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove minor streets and retain only the largest connected component subgraph\n",
    "G_ter = G\n",
    "G_ter.remove_edges_from(minor_streets)\n",
    "G_ter = ox.remove_isolated_nodes(G_ter)\n",
    "G_ter_connected = ox.get_largest_component(G_ter, strongly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then simplify the graph now that we have only the edge types we want\n",
    "G_ter_simp = ox.simplify_graph(G_ter_connected, strict=True)\n",
    "#G_ter_simp = G_ter\n",
    "#G_ter_simp = G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "taz.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#plot lat-longs on map\n",
    "def make_point(row):\n",
    "    return Point(row.long, row.lat)\n",
    "\n",
    "# Go through every row, and make a point out of its lat and lon\n",
    "points = .apply(make_point, axis=1)\n",
    "\"\"\"\n",
    "def create_lat_long_from_graph_nodes(G):\n",
    "    G_nodes_list = list(G.nodes())\n",
    "    lat_list = []\n",
    "    long_list = []\n",
    "    osmid_list = []\n",
    "    for x in G_nodes_list:\n",
    "        lat_list += [G.nodes()[x]['x'],]\n",
    "        long_list += [G.nodes()[x]['y'],]\n",
    "        osmid_list += [x,]\n",
    "        \n",
    "    return lat_list, long_list, osmid_list\n",
    "\n",
    "lat_list, long_list, osmid_list = create_lat_long_from_graph_nodes(G_ter_simp)\n",
    "\n",
    "\n",
    "def make_df_lat_long_osmid(lat, long, osmid):\n",
    "    final_df = pd.DataFrame(columns=['osmid', 'lat','long'])\n",
    "    final_df['osmid'] = osmid\n",
    "    final_df['lat'] = lat\n",
    "    final_df['long'] = long\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "nodes_df = make_df_lat_long_osmid(lat_list, long_list, osmid_list)\n",
    "    \n",
    "\n",
    "\n",
    "#G_ter_simp.nodes()[1377399032]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nodes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot lat-longs on map\n",
    "def make_point(row):\n",
    "    return Point(row.long, row.lat)\n",
    "\n",
    "# Go through every row, and make a point out of its lat and lon\n",
    "points = nodes_df.apply(make_point, axis=1)\n",
    "\n",
    "nodes_points = gpd.GeoDataFrame(nodes_df, geometry=points)\n",
    "nodes_points.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taz.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_taz_1 = gpd.sjoin(nodes_points, taz.iloc[10], how=\"left\", op=\"contains\")\n",
    "merged_taz_1.head()\n",
    "#taz.iloc[0].contains(nodes_points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "5d802d72-49a5-42e1-8231-ecb81c6c092e"
    }
   },
   "outputs": [],
   "source": [
    "#get centroid coordinates of each TAZ (x and y)\n",
    "lats = taz.geometry.centroid.x\n",
    "longs = taz.geometry.centroid.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "3157f03e-ee6c-48ea-93a3-558be8788f91"
    }
   },
   "outputs": [],
   "source": [
    "taz.iloc[10]['geometry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "611a1729-d32a-484e-bdf4-6f5c0db78cce"
    }
   },
   "outputs": [],
   "source": [
    "def make_taz_lat_long_df(tazs, lat, long):\n",
    "    new_df = pd.DataFrame(columns=['taz', 'lat','long'])\n",
    "    new_df['taz'] = tazs\n",
    "    new_df['lat'] = lats\n",
    "    new_df['long'] = longs\n",
    "    return new_df\n",
    "\n",
    "centroid_lat_long_df = make_taz_lat_long_df(tazs, lats, longs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "fab6d9a8-e7a5-46a2-ab8f-c5797905a3cf"
    }
   },
   "outputs": [],
   "source": [
    "#plot lat-longs on map\n",
    "def make_point(row):\n",
    "    return Point(row.long, row.lat)\n",
    "\n",
    "# Go through every row, and make a point out of its lat and lon\n",
    "points = centroid_lat_long_df.apply(make_point, axis=1)\n",
    "\n",
    "# Make a new GeoDataFrame\n",
    "# using the data from our old df\n",
    "# but also adding in the geometry we just made\n",
    "taz_centroids = gpd.GeoDataFrame(centroid_lat_long_df, geometry=points)\n",
    "\n",
    "# It doesn't come with a CRS because it's a CSV, so let's\n",
    "# say \"hey, let's use the standard shape of the earth etc\"\n",
    "taz_centroids.crs = {'init': 'epsg:4326'}\n",
    "    \n",
    "\n",
    "#look at the first few\n",
    "taz_centroids.head(n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "12307250-3179-4710-9ec1-d0a92859dd17"
    }
   },
   "outputs": [],
   "source": [
    "#plot taz centroids lat-long\n",
    "ax = taz_centroids.plot(figsize=(25,25), markersize=20, color='green', alpha=0.75)\n",
    "ax.axis('on')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "fd5f4aaa-c237-4183-aaed-21e2b6afcb67"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#taz_loc_df.sort_values('taz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "7264352c-1363-4bb1-911a-c2693a871a6a"
    }
   },
   "outputs": [],
   "source": [
    "taz['geometry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def parse_taz_loc_df_into_lat_long(taz):\n",
    "    \n",
    "    new_df = pd.DataFrame(columns=['taz','lat','long'])\n",
    "    \n",
    "    for x in taz:\n",
    "        new_df = pd.DataFrame(columns=['taz','lat','long'])\n",
    "        new_df['taz'] = x['taz']\n",
    "        new_df['lat'] = = taz['geometry'][0].split(',')\n",
    "    \n",
    "        #remove 'POLYGON' from first element\n",
    "        new_str[0] = new_str[0].split('N (')[1]\n",
    "\n",
    "        #get longitude for all values in polygon\n",
    "        new_str_list = [x.split(' ') for x in new_str]\n",
    "        #print(new_str_list)\n",
    "\n",
    "        #remove first element\n",
    "        del new_str_list[0]\n",
    "\n",
    "        #remove last element\n",
    "        del new_str_list[-1]\n",
    "\n",
    "        #get lat and long\n",
    "        long = [float(x[1]) for x in new_str_list]\n",
    "        lat = [float(x[2]) for x in new_str_list]\n",
    "        #print(new_str[3].split(' '))\n",
    "        #print(long)\n",
    "        #print(lat)\n",
    "        return long, lat\n",
    "\n",
    "\n",
    "def make_lat_long_df(lat, long):\n",
    "    new_df = pd.DataFrame(columns=['lat','long'])\n",
    "    #new_df['segment_id'] = df['PublicSegID']\n",
    "    new_df['lat'] = lat\n",
    "    new_df['long'] = long\n",
    "    return new_df\n",
    "\n",
    "\n",
    "lat, long = parse_taz_loc_df_into_lat_long(taz_loc_df)\n",
    "lat_long_df = make_lat_long_df(lat, long)\n",
    "lat_long_df\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lpsim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
